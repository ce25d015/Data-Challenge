# Relevance Score Prediction Using Metric and Text Embeddings

## Project Overview
This project predicts the relevance or fitness score (1-10) for pairs of metric definitions and prompt-response text pairs. The metric definitions are provided as precomputed text embeddings, and the prompt-response pairs are converted into embeddings using the same embedding model. The predictions are generated by training a regression model on combined embeddings, optimized to minimize Root Mean Square Error (RMSE) against ground truth scores.

## Files Overview
- `metric_name_embeddings.npy`: Numpy file containing embeddings for each metric definition.
- `train.csv`: Training dataset containing prompt-response pairs and corresponding scores.
- `test.csv`: Test dataset containing prompt-response pairs for which scores need to be predicted.
- `submission.csv`: Output file with predicted scores for the test set, formatted for submission.

## Methodology
1. **Embedding Extraction:**  
   - Metric definitions are pre-embedded using the SentenceTransformer model `"google/embeddinggemma-300m"`.
   - Prompt-response pairs are embedded using the same model for semantic alignment.

2. **Feature Engineering:**  
   - For each example, metric embedding and prompt-response embedding are combined.  
   - Features used include concatenation of embeddings and cosine similarity between them.

3. **Model Training:**  
   - A regression model (e.g., Random Forest Regressor) is trained on the combined features and known scores (0-10 discretized).

4. **Prediction:**  
   - The trained model predicts scores for test examples.  
   - Scores are rounded to one decimal place for submission.
## How to Run
### Requirements
- Python 3.7+
- Packages: `sentence-transformers`, `numpy`, `pandas`, `scikit-learn`
### Steps
1. Load metric embeddings:
    ```
    metric_embeddings = np.load('metric_name_embeddings.npy')
    ```
2. Load training and test CSV files containing prompt-response pairs.
3. Encode prompt-response pairs using the model:
    ```
    model = SentenceTransformer("google/embeddinggemma-300m")
    train_resp_emb = model.encode(list_of_train_prompt_responses)
    test_resp_emb = model.encode(list_of_test_prompt_responses)
    ```
4. Create combined feature vectors and train the regression model.
5. Predict and save results in `submission.csv` with the format:
    ```
    ID,score
    1,9.0
    2,7.0
    3,9.0
    ...
    ```

## Evaluation
- The model is evaluated by RMSE between predicted and actual scores.
- The goal is to minimize RMSE on the test dataset.
